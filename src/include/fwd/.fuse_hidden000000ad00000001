
#include "gpu/gpu2d.hpp"
#include <cudnn.h>

#include "error_util.h"
#include <network/parallel/network.hpp>

using namespace znn::v4;
using znn::gpu2d::vek2i;

template<typename T>
void print_all( const T* t, size_t c)
{
    for ( size_t i = 0; i < c; ++i )
    {
        if ( i > 0 ) std::cout << ' ';
        std::cout << t[i];
    }

    std::cout << std::endl;
}



typedef zi::vl::vec<int,3> vek3i;






int main()
{
    int version = (int)cudnnGetVersion();
    printf("cudnnGetVersion() : %d , CUDNN_VERSION from cudnn.h : %d (%s)\n", version, CUDNN_VERSION, CUDNN_VERSION_STR);
    printf("Host compiler version : %s %s\r", COMPILER_NAME, COMPILER_VER);
    showCudaDevices();

    int device = 0;
    checkCudaErrors( cudaSetDevice(device) );
    std::cout << "Using device " << device << std::endl;

    struct cudaDeviceProp prop;
    checkCudaErrors(cudaGetDeviceProperties( &prop, device ));
    double globalMem = prop.totalGlobalMem/double(1024*1024);

    std::cout << "Memory: " << globalMem << std::endl;

    {
        cudnnHandle_t cudnnHandle;
        checkCUDNN( cudnnCreate(&cudnnHandle) );

        znn::gpu3db::pooling_layer pl( cudnnHandle,
                                       2, 2, vek3i(11,11,11), vek3i(2,2,2));

        real* data = new real[11*11*11*4];
        for ( int i = 0; i < 11*11*11*4; ++i )
            data[i] = i + 1;

        real* data_in;
        real* data_out;

        checkCudaErrors( cudaMalloc(&data_in, 4*11*11*11*4) );
        checkCudaErrors( cudaMalloc(&data_out, 4*10*10*10*4) );

        checkCudaErrors( cudaMemcpy(data_in, data, 4*11*11*11*4,
                                    cudaMemcpyHostToDevice) );

        pl.forward(data_in, data_out);

        real* xx = new real[4000];

        checkCudaErrors( cudaMemcpy(xx, data_out, 4*1000*4,
                                    cudaMemcpyDeviceToHost) );

        print_all(xx, 4000);


        checkCUDNN( cudnnDestroy(cudnnHandle) );

    }

    if (0)
    {
        cudnnHandle_t cudnnHandle;
        checkCUDNN( cudnnCreate(&cudnnHandle) );

        znn::gpu3db::conv_layer cl( cudnnHandle,
                                    10, 10, 5, vek3i(5,5,5), vek3i(3,5,4));

        real* data = new real[5*5*5*10*10];
        for ( int i = 0; i < 5*5*5*10*10; ++i )
            data[i] = i % 7 + 1;

        real* bias_data = new real[5];
        bias_data[0] = 2;
        bias_data[1] = 3;
        bias_data[2] = 3;
        bias_data[3] = 3;
        bias_data[4] = 3;

        real* f = new real[3*4*5*10*5];

        for ( int i = 0; i < 3*4*5*10*5; ++i )
            f[i] = i % 3 + 1;

        real* data_in;
        real* data_out;

        checkCudaErrors( cudaMalloc(&data_in, 5*5*5*10*4*10) );
        checkCudaErrors( cudaMalloc(&data_out, 5*2*3*4) );

        checkCudaErrors( cudaMemcpy(data_in, data, 5*5*5*10*10*4,
                                    cudaMemcpyHostToDevice) );

        checkCudaErrors( cudaMemcpy(cl.filter_data(), f, 3*4*5*10*5*4,
                                    cudaMemcpyHostToDevice) );

        checkCudaErrors( cudaMemcpy(cl.bias_data(), bias_data, 4*5,
                                    cudaMemcpyHostToDevice) );

        cl.forward(data_in, data_out);

        real* xx = new real[5*1*2*3];

        checkCudaErrors( cudaMemcpy(xx, data_out, 4*5*1*2*3,
                                    cudaMemcpyDeviceToHost) );

        print_all(xx, 5*1*2*3);


        checkCUDNN( cudnnDestroy(cudnnHandle) );

    }


    if (0)
    {
         znn::gpu3d::fwd_network fw(1);
         fw.conv(16,7)
             .conv(24,7)
             .conv(32,7)
             .conv(32,7)
             .conv(32,7)
             .conv(32,7)
             .conv(1,1)
             .done(1,16);
         fw.benchmark(2);
    }



    if (0)
    {
         znn::gpu2d::fwd_network fw(1);
         fw.conv(12,vek2i(6,6))
             .pool(vek2i(2,2))
             .conv(12,vek2i(6,6))
             .pool(vek2i(2,2))
             .conv(24,vek2i(6,6))
             .pool(vek2i(2,2))
             .conv(24,vek2i(6,6))
             .pool(vek2i(2,2))
             .conv(48,vek2i(5,5))
             .conv(4,vek2i(1,1))
             .done(1,vek2i(3*1024,3*1024));

         fw.benchmark(2);
    }


    // {
    //      znn::gpu3db::fwd_network fw(1);
    //      fw.conv(12,vek3i(6,6,1))
    //          .pool(vek3i(2,2,1))
    //          .conv(24,vek3i(4,4,1))
    //          .pool(vek3i(2,2,1))
    //          .conv(36,vek3i(4,4,4))
    //          .pool(vek3i(2,2,2))
    //          .conv(48,vek3i(4,4,2))
    //          .pool(vek3i(2,2,2))
    //          .conv(48,vek3i(4,4,2))
    //          .conv(4,vek3i(1,1,1))
    //          .done(1,vek3i(256,512,32));

    //      fw.benchmark(2);
    // }



     // {
     //     znn::gpu3d::fwd_network fw(1);
     //     fw.conv(40,5).pool(2).conv(40,5).pool(2).conv(40,5).conv(40,5).conv(40,5).conv(3,5).done(1,60);
     //     fw.benchmark(2);
     // }


    // {
    //     znn::gpu3d::fwd_network fw(1);
    //     fw.conv(40,5).pool(2).conv(40,5).pool(2).conv(40,5).conv(40,5).conv(40,5).conv(3,5).done(2,64);
    //     fw.benchmark(2);
    // }


#if 0
    {
    }

#endif
    cudaDeviceReset();

}
