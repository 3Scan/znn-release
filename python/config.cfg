# To make every parameter explicite, it is not allowed to use default parameters.
# Please do not delete any item of this configuration file.

[parameters]
#[general]
# specification file of network architecture
fnet_spec = ../networks/srini2d.znn
# number of threads. if 0, the thread number will be equal to
# the number of concurrent threads supported by the implementation.
num_threads = 7
# data type of arrays: float32 or float64
dtype = float32
# type of network output: boundary or affinity
out_type = boundary

#[train]
# output size: z,y,x
train_outsz = 1,100,100
# cost function: square_loss, binomial_cross_entropy, softmax_loss, auto
# auto mode will match the out_type: boundary-softmax, affinity-binomial
cost_fn = auto
# learning rate
eta = 0.001
# saved network name
train_save_net = ARCHIVE/net.h5
# load the network
train_load_net =
# files for train
train_range = 93
# files for test
test_range = 2
anneal_factor = 0.996
# momentum
momentum = 0.9
# weight decay
weight_decay = 0

# optimize to choose direct convolution of FFT
is_optimize = no
# transform data to enrich training data augmentation?
is_data_aug = yes
# mirror the boundary to get a full size output
is_bd_mirror = no
# balance the boundary and non-boundary voxel?
is_rebalance = yes
# use malis weighting of gradient?
is_malis = no
# whether to use real time visualization
is_visual = yes

# number of iteration per show
Num_iter_per_show = 100
# number of iteration per test
Num_iter_per_test = 200
# number of forward pass of each test
test_num = 10
# number of iteration per save
Num_iter_per_save = 200
# maximum iteration
Max_iter = 15000

#[forward]
# image for forward pass
forward_range = 2
# forward network
forward_net = ARCHIVE/net_current.h5
# output size: z,y,x
forward_outsz = 3,100,100
# output file name prefix
output_prefix = ARCHIVE/out

# samples example
# [image1]
# fnames =  path/of/image1.tif/h5,
#           path/of/image2.tif/h5
# preprocessing type
# pp_types = standard2D, none
# is_auto_crop = yes
# [label1]
# fnames = path/of/image3.tif/h5,
#          path/of/image4.tif/h5
# preprocessing type: one_class, binary_class, none, affinity, auto
# auto mode will match the `out_type`: boundary-binary_class, affinity-affinity
# pp_types = binary_class, binary_class
# fmasks = path/of/mask1.tif/h5,
#	   path/of/mask2.tif/h5
#
# [sample1]
# the name should be the same with the one in the network config file
# input1 = 1
# input2 = 2
# output1 = 1
# output2 = 2

[image1]
fnames = ../dataset/zfish/Merlin_raw1.tif
pp_types = standard2D
is_auto_crop = yes

[label1]
fnames = ../dataset/zfish/Merlin_label1.tif
pp_types = auto
is_auto_crop = yes
fmasks =

[sample1]
input = 1
output = 1

[image2]
fnames = ../dataset/zfish/Merlin_raw2.tif
pp_types = standard2D
is_auto_crop = yes

[label2]
fnames = ../dataset/zfish/Merlin_label2.tif
pp_types = auto
is_auto_crop = yes
fmasks =

[sample2]
input = 2
output = 2

[image93]
fnames = ../dataset/zfish/Merlin_label2.tif
pp_types = none
is_auto_crop = yes

[label93]
fnames = ../dataset/zfish/Merlin_label2.tif
pp_types = none
is_auto_crop = yes
fmask =

[sample93]
input = 93
output = 93